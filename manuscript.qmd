---
title: "Manuscript"
format: html
editor_options: 
  chunk_output_type: console
bibliography: resources/bib.bib
csl: resources/citation-style.csl
link-citations: true
---





# 1. Introduction



# 2. Setting Up a Collaborative Workspace



# 3. Conducting Simulations Before Data Acquisition

Doing simulations before data acquisition is useful for several reasons, including: 

1. *Model design*. We can sample not only from the posterior distribution but also 
from the prior, which reflects our expectations about what might happen. Observing 
what the model anticipates before the data arrives is an effective way to gain a 
better understanding of the implications of the prior.
2. *Model checking*. After a model is updated using real data, it is worthwhile 
to simulate implied data to check whether the fit was successful and to investigate 
the model's behaviour.
3. *Software validation*. In order to ensure that our model fitting software is
functioning correctly, it is helpful to simulate observations under a known model 
and then attempt to recover the parameter values from which the data were simulated. 
4. *Research design*. If you can simulate observations from your hypothesis, you 
can evaluate whether the research design can be effective. This is similar to conducting 
a *power analysis*, but the possibilities are broader.   
5. *Forecasting*. Estimates can be used to simulate new predictions for new cases 
and future observations. [@noauthor_statistical_2018]

To demonstrate some of the properties of conducting simulations, we can consider 
the following hypothesis: **Increasing daily exercise time reduces blood pressure 
levels in adults** 


To investigate this hypothesis, it is valuable to invest effort into finding methods 
that distinguish causal inferences from associations. To achieve this, it is extremely 
helpful to first draw a causal model that is separate from the statistical model. 
The simplest graphical causal model is a *DIRECTED ACYCLIC GRAPH*, commonly referred 
to as a *DAG*. [@noauthor_statistical_2018] [@digitale_tutorial_2022]

A DAG is not a detailed statistical model; it is primarily constructed to represent 
prior knowledge about biological and behavioural systems that might confound the 
specific causal research question. [@digitale_tutorial_2022] Let us take our research 
question as an example. Our goal is to investigate the causal effect of increasing 
exercise time, which we denote as E, on blood pressure, referred to as B. A DAG in its 
simplest form might therefore look like this (Figure 1).


```{r}
#| echo: false
#| warning: false
#| message: false
#| fig-cap: "A DAG, assuming that the causal effect of increasing exercise time (E) on blood pressure (B) is not confounded"
#| label: fig-dag1
#| fig-width: 6
#| fig-height: 3


library(tidyverse)
library(ggdag)


coord <- tibble(name = c("E", "B"),
                x = c(1, 2),
                y = c(1, 1))

dag <- dagify(B ~ E,
              coords = coord)


fig1 <- dag |> 
  tidy_dagitty() |>
  ggplot(aes(x = x, y = y,
             xend = xend, yend = yend)) +
  geom_dag_point(color = "white") +
  geom_dag_text(color = "black", size = 8) +
  geom_dag_edges(arrow_directed = grid::arrow(length = grid::unit(5, "pt"), 
                                              type = "closed")) +
  
  theme_dag()



fig1

```


This DAG assumes that the causal effect of increasing exercise time on blood pressure 
is not confounded, which is arguably a naive assumption. For instance, both age and 
diet are potential confounding variables (source). A DAG that includes these confounders 
might look like this (Figure 2).


```{r}
#| echo: false
#| warning: false
#| message: false
#| fig-cap: "A DAG, assuming that the causal effect of increasing exercise time (E) on blood pressure (B) is confounded by both age (A) and diet (D)"
#| label: fig-dag2
#| fig-width: 6
#| fig-height: 3



coord <- tibble(name = c("E", "B", "A", "D"),
                x = c(1, 2, 1.2, 1.7),
                y = c(1, 1, 2, 2))

dag <- dagify(B ~ E,
              B ~ A,
              E ~ A,
              B ~ D,
              coords = coord)


fig1 <- dag |> 
  tidy_dagitty() |>
  ggplot(aes(x = x, y = y,
             xend = xend, yend = yend)) +
  geom_dag_point(color = "white") +
  geom_dag_text(color = "black", size = 8) +
  geom_dag_edges(arrow_directed = grid::arrow(length = grid::unit(5, "pt"), 
                                              type = "closed")) +
  
  theme_dag()



fig1

```


In this DAG, we assume that age directly influences blood pressure, as we know that 
aging is associated with higher blood pressures (sources). Additionally, age influences 
exercise time, which indirectly affects blood pressure, given that aging is also 
associated with increased inactivity. The DAG further assumes that diet acts as a 
confounding factor for blood pressure, as it is influenced by factors such as high-fat 
diets (source).

Given that we believe our DAG to be accurate, we can construct our model with stronger 
scientific justifications regarding which confounding factors should be accounted 
for and how we will do so.

**Model design** 
Now that we have established that the causal effect of increasing exercise time on 
blood pressure is confounded by both age and diet, we have a solid foundation for 
designing our model. We have decided to recruit 100 sedentary individuals aged 20 
to 70 to participate in a one-year training study. The participants will follow the 
recommendation of doing 150 minutes of endurance exercise per week as proposed by 
the WHO. Blood pressure will be measured before and after the one-year intervention 
period. To account for the effects of age and diet, we will register the participants' 
age at inclusion and evaluate their diet using a binominal scale, where 1 indicates 
a healthy diet and 0 indicates a unhealthy diet. 

The model can now be described mathematically, for exemple in termes of a simple 
liniar regression mode:

$$
\begin{align}
\operatorname{BloodPressure}_i &= \beta_0 + \beta_1 \cdot \operatorname{Exercise}_i 
+ \beta_2 \cdot \operatorname{Age}_i + \beta_3 \cdot \operatorname{Diet}_i + \epsilon_i \\
\end{align}
$$



Here, 
$$
\begin{align}
\beta_0 &: \operatorname{Intercept}\\
\beta_1 &: \operatorname{Coefficient for exercise time}\\
\beta_2 &: \operatorname{Coefficient for age}\\
\beta_3 &: \operatorname{Coefficient for diet}\\
\epsilon_i &: \operatorname{Random error term}\\
\end{align}
$$




The linear regression model can be implemented in R as follows: 

```{r}
#| results: false
#| label: "Example data and model"

# Example dataset
data <- data.frame(
  exercise = rnorm(100, mean=150, sd=20),
  age = rnorm(100, mean=45, sd=15),
  diet = rnorm(100, mean=2, sd=1),
  bloodpressure = rnorm(100, mean=120, sd=10)
)

# Fit a simple linear regression model
model <- lm(bloodpressure ~ exercise + age + diet, data = data)

# Summarize the model results
summary(model)
```

**Run simulations**

Now it is time to run some simulation, and we will do this to test our model design.
To do this we first have to define our parameter values:

$$

\begin{align}
\operatorname{BP}_i & = \beta_0 + \beta_E \cdot \operatorname{E}_i + \beta_A \cdot \operatorname{A}_i + \beta_D \cdot \operatorname{D}_i + \epsilon_i \\
\operatorname{E}_i & \sim \operatorname{Normal}(\mu_E, \sigma_E) \\
\operatorname{A}_i & \sim \operatorname{Normal}(\mu_A, \sigma_A) \\
\operatorname{D}_i & \sim \operatorname{Binomial}(n=1, p=0.5) \\
\epsilon_i & \sim \operatorname{Normal}(\mu_\epsilon, \sigma_\epsilon) \\
\beta_0 & = 120 \quad (\text{intercept}) \\
\beta_E & = -0.1 \quad (\text{beta for exercise}) \\
\beta_A & = 0.2 \quad (\text{beta for age}) \\
\beta_D & = -5 \quad (\text{beta for diet}) \\
\mu_E & = 150 \quad (\text{mean exercise}) \\
\mu_A & = 45 \quad (\text{mean age}) \\
\mu_\epsilon & = 0 \quad (\text{mean error term}) \\
\sigma_E & = 20 \quad (\text{exercise standard deviation}) \\
\sigma_A & = 10 \quad (\text{age standard deviation}) \\
\sigma_\epsilon & = 5 \quad (\text{error term standard deviation}) \\
\end{align}

$$


After setting the parameter values, we can simulate data based on these parameters. 
To do this, it is convenient to create a function where you specify information about 
each parameter that can be manipulated. This allows us to experiment with different 
values later to test the robustness of our model. Take a look at the code!

```{r}
#| results: false


# Simulate data based on the hypothetical model

# a basic function
sim <- function(n = 100,
                intercept = 120,
                mean_exercise = 150,
                beta_exercise = -0.1,
                sigma_exercise = 20,
                mean_age = 45,
                beta_age = 0.2,
                sigma_age = 10,
                size_diet = 1,
                prob_diet = 0.5,
                beta_diet = -5, 
                mean_epsilon = 0,
                sigma_epsilon = 5) {
  
  #this is the body
  diet <- rbinom(n, size = size_diet, prob = prob_diet) #simulate diet 
  age <- rnorm(n, mean = mean_age, sd = sigma_age) #simulate age
  exercise <- rnorm(n, mean = mean_exercise, sd = sigma_exercise) #simulate exercise duration
  epsilon <- rnorm(n, mean = mean_epsilon, sd = sigma_epsilon) #error term 
  bloodpressure <- intercept + (beta_exercise * exercise) + (beta_age * age) + (beta_diet * diet) + epsilon
  
  
  
  #the output
  return(data.frame(age, exercise, diet, bloodpressure, epsilon))
  
}



```

Now that we have our simulated dataset, we can easily test our hypotheses using 
the linear mixed model: *lm(bloodpressure ~ exercise + age + diet, sim_data)*. 

```{r}
#| echo: false

sim_data <- sim()


sim.m1 <- lm(bloodpressure ~ exercise + age + diet, sim_data)

summary.m1 <- summary(sim.m1)

```

The output will look like this and we can see that there seems like there is an 
effect of exercise on blood pressure! 



```{r}
#| echo: false
summary.m1

exercise_effect <- summary(sim.m1)$coefficients["exercise", "Estimate"]

```

In this model we can see that each minute of increase exercise time is asssiated with
**`r exercise_effect`** reduction i blood pressure, when we acount for age and diet!




```{r}

set.seed(1)
results <- list()

for(i in 1:1000) {
  
  dat1 <- sim()
  
  
  m1 <- lm(bloodpressure ~ exercise + age + diet, data = dat1)

  
  results[[i]] <- data.frame(model = c("m1"),
             estimate = c(coef(m1)[2]))
  
  
  
}


bind_rows(results) |>
  ggplot(aes(model, estimate)) +
  geom_point(position = position_jitter(width = 0.1),
             alpha = 0.2, 
             shape = 21,
             color = "blue") + 
  theme_classic()







```


Now it is ready to test our data in our model 


Compare true coefficients (true_beta) with the estimated coefficients.
Adjust parameters to evaluate how robust your model is.





* create an simple hypothesis 
* create a DAG for this hypothesis 
* Describe the model 
* Do simulations 




# 4. Including Data Packages for Distribution



# 5. Creating Visualizations from Data Packages

# Bibliography